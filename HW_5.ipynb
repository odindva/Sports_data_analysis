{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание 5\n",
    "Ссылка на данные - https://drive.google.com/file/d/1gMEVl47pIoV1-AseB9doQ6DZNJrY3NkW/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжим работу с данными, которые были использованы в ДЗ2 и 3, продолжим решать задачу обнаружения мошеннических транзакций, что позволит получить полное решение задачи / полный пайплайн."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "from sklearn.metrics import r2_score, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from inspect import signature\n",
    "from typing import List, Optional, Union\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from category_encoders.cat_boost import CatBoostEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(ts, base_date_s=None):\n",
    "    \"\"\"\n",
    "    Меняет дату с секунд (от базовой даты) на datetime\n",
    "    \"\"\"\n",
    "    if base_date_s is None:\n",
    "        base_date_s = dt.datetime.timestamp(\n",
    "            dt.datetime(year=2017, month=12, day=1))\n",
    "    return dt.datetime.fromtimestamp(ts + base_date_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_x(dfs: list,\n",
    "                column,\n",
    "                func,\n",
    "                new_column=None):\n",
    "    \"\"\"\n",
    "    Создает новый признак new_column на основе признака column, \n",
    "    пропущенного через функцию func\n",
    "    Отрабатывает для всех датасетов в dfs\n",
    "    \"\"\"\n",
    "    if new_column is None:\n",
    "        new_column = column\n",
    "    for df in dfs:\n",
    "        df[new_column] = df[column].apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Обработка категориальных признаков и подготовка матрицы\n",
    "    признаков для передачи в любой алгоритм машинного обучения.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    encoder: callable\n",
    "        Объект для обработки категориальных признаков;\n",
    "        объект должен поддерживать sklearn-API.\n",
    "\n",
    "    categorical_features: List[str]\n",
    "        Список с названием категориальных признаков.\n",
    "\n",
    "    na_value: float or str, optional, default = None\n",
    "        Значение для заполнения пропусков.\n",
    "        Опциональный параметр, по умолчанию, не используется.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 encoder: callable,\n",
    "                 categorical_features: List[str],\n",
    "                 na_value: Union[int, float, str] = None) -> None:\n",
    "        self.encoder = encoder\n",
    "        self.categorical_features = categorical_features\n",
    "        self.na_value = na_value\n",
    "\n",
    "        sig = signature(encoder.fit)\n",
    "        self.nparams = len(sig.parameters)\n",
    "        self.encoders = None\n",
    "\n",
    "    def _prepare_data(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Подготовка данных для передачи в модель.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.na_value:\n",
    "            return X[self.categorical_features].fillna(self.na_value)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _check_unique_values(self, y: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Проверка на ранее не встречающиеся значения признака.\n",
    "        Если значения встречаются - заменяем на self.na_value,\n",
    "        если self.na_value - не задан, то заменяем на моду.\n",
    "\n",
    "        \"\"\"\n",
    "        encoder = self.encoders[y.name]\n",
    "        missed_values = list(\n",
    "            set(y.unique()) - set(encoder.classes_)\n",
    "        )\n",
    "\n",
    "        if missed_values:\n",
    "            mask = y.isin(missed_values)\n",
    "            if self.na_value:\n",
    "                y[mask] = self.na_value\n",
    "            else:\n",
    "                mode = y.value_counts()[0].index\n",
    "                y[mask] = mode\n",
    "\n",
    "        return y\n",
    "\n",
    "    def _fit_label_encoder(self, X: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Обучение LabelEncoder'ов для всех признаков;\n",
    "\n",
    "        \"\"\"\n",
    "        self.encoders = {}\n",
    "        for feature in self.categorical_features:\n",
    "            x = X[feature].astype(str)\n",
    "            encoder = deepcopy(self.encoder)\n",
    "            self.encoders[feature] = encoder.fit(x)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _transform_label_encoder(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Применение LabelEncoder'ов для всех признаков;\n",
    "\n",
    "        \"\"\"\n",
    "        for feature in self.categorical_features:\n",
    "            x = X[feature].astype(str)\n",
    "            x = self._check_unique_values(x)\n",
    "            encoder = self.encoders.get(feature)\n",
    "            X[feature] = encoder.transform(x)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Обучение encoder'а категориальных признаков.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: pandas.core.frame.DataFrame\n",
    "            Матрица признаков.\n",
    "\n",
    "        y: pandas.core.frame.Series\n",
    "            Вектор целевой переменной.\n",
    "            Опциональный параметр, по умолчанию, не требуется.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        X = self._prepare_data(X)\n",
    "        if self.nparams == 1:\n",
    "            self._fit_label_encoder(X=X)\n",
    "        else:\n",
    "            self.encoder.fit(\n",
    "                X[self.categorical_features].astype(str), y\n",
    "            )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Преобразование категориальных признаков.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: pandas.core.frame.DataFrame\n",
    "            Матрица признаков.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_transformed: pandas.core.frame.DataFrame\n",
    "            Преобразованная матрица признаков с\n",
    "            обработанными категориальными признаками.\n",
    "\n",
    "        \"\"\"\n",
    "        X = self._prepare_data(X)\n",
    "        if self.encoders:\n",
    "            categorical = self._transform_label_encoder(X)\n",
    "        else:\n",
    "            categorical = self.encoder.transform(\n",
    "                X[self.categorical_features].astype(str)\n",
    "            )\n",
    "\n",
    "        X = X.drop(self.categorical_features, axis=1)\n",
    "        X = pd.concat([X, categorical], axis=1)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./assignment_2_train.csv')\n",
    "lb_data = pd.read_csv('./assignment_2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "2  NaN   NaN   NaN   NaN  \n",
       "3  NaN   NaN   NaN   NaN  \n",
       "4  0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180000, 394), (100001, 394))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, lb_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 180000 entries, 0 to 179999\n",
      "Columns: 394 entries, TransactionID to V339\n",
      "dtypes: float64(376), int64(4), object(14)\n",
      "memory usage: 541.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = data.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "categorical_features = data.select_dtypes(include=[\"object\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[categorical_features] = data[categorical_features].astype(str)\n",
    "lb_data[categorical_features] = lb_data[categorical_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = 144000 rows, 392 cols\n",
      "x_valid.shape = 28800 rows, 392 cols\n",
      "x_test.shape = 7200 rows, 392 cols\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid = train_test_split(\n",
    "    data.drop([\"TransactionID\", target_name], axis=1), train_size=0.8, shuffle=True, random_state=1,\n",
    ")\n",
    "y_train, y_valid = train_test_split(\n",
    "    data[target_name], train_size=0.8, shuffle=True, random_state=1,\n",
    ")\n",
    "\n",
    "x_valid, x_test = train_test_split(\n",
    "    x_valid, train_size=0.8, shuffle=True, random_state=27\n",
    ")\n",
    "y_valid, y_test = train_test_split(\n",
    "    y_valid, train_size=0.8, shuffle=True, random_state=27\n",
    ")\n",
    "\n",
    "print(\"x_train.shape = {} rows, {} cols\".format(*x_train.shape))\n",
    "print(\"x_valid.shape = {} rows, {} cols\".format(*x_valid.shape))\n",
    "print(\"x_test.shape = {} rows, {} cols\".format(*x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_LB = lb_data.drop([\"TransactionID\", target_name], axis=1)\n",
    "y_LB = lb_data[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "model_count = 0\n",
    "def evaluate(x_train, \n",
    "         x_valid, \n",
    "         x_test,\n",
    "         model, \n",
    "         x_LB=None,\n",
    "         metric=roc_auc_score, \n",
    "         name=None):\n",
    "    preds = {\n",
    "        'pred_train': model.predict_proba(x_train)[:,1],\n",
    "        'pred_valid': model.predict_proba(x_valid)[:,1],\n",
    "        'pred_test': model.predict_proba(x_test)[:,1],\n",
    "    }\n",
    "    if not x_LB is None:\n",
    "        preds['pred_LB'](model.predict_proba(x_LB)[:,1])\n",
    "        \n",
    "    global model_count\n",
    "    if name is None:\n",
    "        name = f'model_{model_count}'\n",
    "    models[name] = {\n",
    "        'scores': {\n",
    "            'train': (metric(y_train, preds['pred_train'])),\n",
    "            'valid': (metric(y_valid, preds['pred_valid'])),\n",
    "            'test': (metric(y_test, preds['pred_test'])),\n",
    "            },\n",
    "        'preds': preds,\n",
    "        'model': model\n",
    "    }\n",
    "    if not x_LB is None:\n",
    "        scores[name][scores]['LB']: (metric(y_LB, preds['pred_LB']))\n",
    "    model_count += 1\n",
    "    return f'\\n{name}:\\n{models[name][\"scores\"]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 0: \n",
    "выбрать любую модель машнного обучения и зафиксировать любой тип валидации. Обучить базовую модель и зафиксировать базовое качество модели. В каждом следующем задании нужно будет обучить выбранную модель и оценивать ее качество на зафиксированной схеме валидации. После каждого задания, требуется сделать вывод о достигаемом качестве модели, по сравнению с качестом из предыдущего шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CategoricalEncoder(\n",
    "    encoder=CatBoostEncoder(random_state=27),\n",
    "    categorical_features=categorical_features,\n",
    ")\n",
    "\n",
    "x_train_ce = encoder.fit_transform(x_train, y_train)\n",
    "x_valid_ce = encoder.transform(x_valid)\n",
    "x_test_ce = encoder.transform(x_test)\n",
    "x_LB_ce = encoder.transform(x_LB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"subsample\": 0.5,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"n_estimators\": 1000,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"reg_lambda\": 10,\n",
    "    \"max_depth\": 4,\n",
    "    \"gamma\": 10,\n",
    "#     \"nthread\": 6,\n",
    "    \"seed\": 27,\n",
    "    'predictor': 'gpu_predictor',\n",
    "    'tree_method': 'gpu_hist'\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model, \n",
    "              x_train, \n",
    "              y_train, \n",
    "              x_valid,\n",
    "              y_valid,\n",
    "              name=None):\n",
    "    eval_sets = [\n",
    "        (x_train, y_train),\n",
    "        (x_valid, y_valid)\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        y=y_train,\n",
    "        X=x_train,\n",
    "        early_stopping_rounds=50,\n",
    "        eval_set=eval_sets,\n",
    "        eval_metric=\"auc\",\n",
    "        verbose=100\n",
    "    )\n",
    "    out = evaluate(x_train_ce, x_valid_ce, x_test_ce, model, name=name)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.65329\tvalidation_1-auc:0.65424\n",
      "[100]\tvalidation_0-auc:0.91608\tvalidation_1-auc:0.90411\n",
      "[200]\tvalidation_0-auc:0.92218\tvalidation_1-auc:0.90940\n",
      "[300]\tvalidation_0-auc:0.92499\tvalidation_1-auc:0.91152\n",
      "[400]\tvalidation_0-auc:0.92522\tvalidation_1-auc:0.91155\n",
      "[500]\tvalidation_0-auc:0.92627\tvalidation_1-auc:0.91251\n",
      "[600]\tvalidation_0-auc:0.92647\tvalidation_1-auc:0.91279\n",
      "[700]\tvalidation_0-auc:0.92699\tvalidation_1-auc:0.91313\n",
      "[800]\tvalidation_0-auc:0.92725\tvalidation_1-auc:0.91335\n",
      "[854]\tvalidation_0-auc:0.92754\tvalidation_1-auc:0.91341\n",
      "\n",
      "base_model:\n",
      "{'train': 0.9275598015956472, 'valid': 0.913433342932293, 'test': 0.9085548911243222}\n"
     ]
    }
   ],
   "source": [
    "model_fit(model, \n",
    "          x_train_ce, \n",
    "          y_train, \n",
    "          x_valid_ce,\n",
    "          y_valid,\n",
    "          name='base_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1: \n",
    "признак TransactionDT - это смещение в секундах относительно базовой даты. Базовая дата - 2017-12-01, преобразовать признак TransactionDT в datetime, прибавив к базовой дате исходное значение признака. Из полученного признака выделить год, месяц, день недели, час, день."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = ['TransactionDT_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5849     2017-12-03 02:57:41\n",
       "113764   2017-12-26 16:10:44\n",
       "118516   2017-12-27 19:14:01\n",
       "Name: TransactionDT_dt, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_x(dfs=[x_train_ce, x_valid_ce, x_test_ce, x_LB_ce],\n",
    "            column='TransactionDT',\n",
    "            func=get_date,\n",
    "            new_column='TransactionDT_dt')\n",
    "x_train_ce['TransactionDT_dt'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_features = ['year', 'month', 'dayofweek', 'hour', 'day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in current_features:\n",
    "    transform_x(dfs=[x_train_ce, x_valid_ce, x_test_ce, x_LB_ce],\n",
    "            column='TransactionDT_dt',\n",
    "            func=lambda x: eval(f'x.{feature}'),\n",
    "            new_column=f'TransactionDT_{feature}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_features = list(map(lambda x: 'TransactionDT_' + x, current_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionDT_year</th>\n",
       "      <th>TransactionDT_month</th>\n",
       "      <th>TransactionDT_dayofweek</th>\n",
       "      <th>TransactionDT_hour</th>\n",
       "      <th>TransactionDT_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113764</th>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118516</th>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionDT_year  TransactionDT_month  TransactionDT_dayofweek  \\\n",
       "5849                  2017                   12                        6   \n",
       "113764                2017                   12                        1   \n",
       "118516                2017                   12                        2   \n",
       "\n",
       "        TransactionDT_hour  TransactionDT_day  \n",
       "5849                     2                  3  \n",
       "113764                  16                 26  \n",
       "118516                  19                 27  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_ce[current_features].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features += current_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_x(dfs=[x_train_ce, x_valid_ce, x_test_ce, x_LB_ce],\n",
    "            column='TransactionDT_dt',\n",
    "            func=dt.datetime.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.65329\tvalidation_1-auc:0.65424\n",
      "[100]\tvalidation_0-auc:0.91607\tvalidation_1-auc:0.90449\n",
      "[200]\tvalidation_0-auc:0.92419\tvalidation_1-auc:0.91048\n",
      "[300]\tvalidation_0-auc:0.92612\tvalidation_1-auc:0.91180\n",
      "[400]\tvalidation_0-auc:0.92704\tvalidation_1-auc:0.91301\n",
      "[500]\tvalidation_0-auc:0.92762\tvalidation_1-auc:0.91314\n",
      "[600]\tvalidation_0-auc:0.92783\tvalidation_1-auc:0.91353\n",
      "[700]\tvalidation_0-auc:0.92839\tvalidation_1-auc:0.91376\n",
      "[739]\tvalidation_0-auc:0.92845\tvalidation_1-auc:0.91373\n",
      "\n",
      "model_1:\n",
      "{'train': 0.9283931351031662, 'valid': 0.9137600689942209, 'test': 0.9095193430847819}\n"
     ]
    }
   ],
   "source": [
    "model_fit(model, \n",
    "          x_train_ce, \n",
    "          y_train, \n",
    "          x_valid_ce,\n",
    "          y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.9275598015956472,\n",
       " 'valid': 0.913433342932293,\n",
       " 'test': 0.9085548911243222}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['base_model']['scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прирост всего 0,001. Может быть случайным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Задание 2: \n",
    "сделать конкатенацию признаков\n",
    "\n",
    "* card1 + card2;\n",
    "\n",
    "* card1 + card2 + card_3 + card_5;\n",
    "\n",
    "* card1 + card2 + card_3 + card_5 + addr1 + addr2\n",
    "\n",
    "Рассматривать их как категориальных признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_features = ['card1_2', 'card1_2_3_5', 'card1_2_3_5_addr1_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_func_concat(dfs, lst, name, inplace=False):\n",
    "    out_dfs = []\n",
    "    for df in dfs:\n",
    "        tmp_df = pd.DataFrame()\n",
    "        tmp_df[name] = ['' for _ in range(df.shape[0])]\n",
    "        for feature in lst:\n",
    "            tmp_df[name] += '_' + df[feature].astype(str)\n",
    "        if inplace:\n",
    "            df[name] = tmp_df[name]\n",
    "        else:\n",
    "            out_dfs.append(tmp_df[name])\n",
    "    if not inplace:\n",
    "        return out_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_func_concat(dfs=[x_train_ce, x_valid_ce, x_test_ce, x_LB_ce], \n",
    "                 lst=['card1', 'card2'], \n",
    "                 name='card1_2', \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_func_concat(dfs=[x_train_ce, x_valid_ce, x_test_ce, x_LB_ce], \n",
    "                 lst=['card1', 'card2', 'card3', 'card5'], \n",
    "                 name='card1_2_3_5', \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_func_concat(dfs=[x_train_ce, x_valid_ce, x_test_ce, x_LB_ce], \n",
    "                 lst=['card1', 'card2', 'card3', 'card5', 'addr1', 'addr2'], \n",
    "                 name='card1_2_3_5_addr1_2', \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card1_2</th>\n",
       "      <th>card1_2_3_5</th>\n",
       "      <th>card1_2_3_5_addr1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>_7919_194.0</td>\n",
       "      <td>_7919_194.0_150.0_166.0</td>\n",
       "      <td>_7919_194.0_150.0_166.0_325.0_87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113764</th>\n",
       "      <td>_3109_390.0</td>\n",
       "      <td>_3109_390.0_150.0_224.0</td>\n",
       "      <td>_3109_390.0_150.0_224.0_498.0_87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118516</th>\n",
       "      <td>_6019_583.0</td>\n",
       "      <td>_6019_583.0_150.0_226.0</td>\n",
       "      <td>_6019_583.0_150.0_226.0_126.0_87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            card1_2              card1_2_3_5  \\\n",
       "5849    _7919_194.0  _7919_194.0_150.0_166.0   \n",
       "113764  _3109_390.0  _3109_390.0_150.0_224.0   \n",
       "118516  _6019_583.0  _6019_583.0_150.0_226.0   \n",
       "\n",
       "                       card1_2_3_5_addr1_2  \n",
       "5849    _7919_194.0_150.0_166.0_325.0_87.0  \n",
       "113764  _3109_390.0_150.0_224.0_498.0_87.0  \n",
       "118516  _6019_583.0_150.0_226.0_126.0_87.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_ce[current_features].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features += current_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CategoricalEncoder(\n",
    "    encoder=CatBoostEncoder(random_state=27),\n",
    "    categorical_features=categorical_features,\n",
    ")\n",
    "\n",
    "x_train_ce = encoder.fit_transform(x_train_ce, y_train)\n",
    "x_valid_ce = encoder.transform(x_valid_ce)\n",
    "x_test_ce = encoder.transform(x_test_ce)\n",
    "x_LB_ce = encoder.transform(x_LB_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features += current_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.74689\tvalidation_1-auc:0.61405\n",
      "[100]\tvalidation_0-auc:0.96182\tvalidation_1-auc:0.88500\n",
      "[200]\tvalidation_0-auc:0.96519\tvalidation_1-auc:0.88973\n",
      "[300]\tvalidation_0-auc:0.96618\tvalidation_1-auc:0.89189\n",
      "[400]\tvalidation_0-auc:0.96669\tvalidation_1-auc:0.89284\n",
      "[500]\tvalidation_0-auc:0.96717\tvalidation_1-auc:0.89290\n",
      "[502]\tvalidation_0-auc:0.96717\tvalidation_1-auc:0.89290\n",
      "\n",
      "model_2:\n",
      "{'train': 0.9669344962919636, 'valid': 0.8933799484021945, 'test': 0.8885643055143918}\n"
     ]
    }
   ],
   "source": [
    "model_fit(model, \n",
    "          x_train_ce, \n",
    "          y_train, \n",
    "          x_valid_ce,\n",
    "          y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.9283931351031662,\n",
       " 'valid': 0.9137600689942209,\n",
       " 'test': 0.9095193430847819}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['model_1']['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.9275598015956472,\n",
       " 'valid': 0.913433342932293,\n",
       " 'test': 0.9085548911243222}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['base_model']['scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало хуже предыдущих моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 3: \n",
    "Сделать FrequencyEncoder для признаков card1 - card6, addr1, addr2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_features = ['card1', 'card2', 'card3', \n",
    "                    'card4', 'card5', 'card6', \n",
    "                    'addr1', 'addr2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_func_Frequency(dfs, lst, inplace=False):\n",
    "    out_dfs = []\n",
    "    for df in dfs:\n",
    "        tmp_df = pd.DataFrame()\n",
    "        for feature in lst:\n",
    "            freq_encoder = df[feature].value_counts(normalize=True)\n",
    "            new_name = f'{feature}_frequency'\n",
    "            tmp_df[new_name] = df[feature].map(freq_encoder)\n",
    "            if inplace:\n",
    "                df[new_name] = tmp_df[new_name]\n",
    "        if not inplace:\n",
    "            out_dfs.append(tmp_df)\n",
    "    if not inplace:\n",
    "        return out_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_func_Frequency(dfs=[x_train_ce, x_valid_ce, x_test_ce, x_LB_ce], \n",
    "                    lst=current_features,\n",
    "                    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_features = list(map(lambda x: x + '_frequency', current_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card1_frequency</th>\n",
       "      <th>card2_frequency</th>\n",
       "      <th>card3_frequency</th>\n",
       "      <th>card4_frequency</th>\n",
       "      <th>card5_frequency</th>\n",
       "      <th>card6_frequency</th>\n",
       "      <th>addr1_frequency</th>\n",
       "      <th>addr2_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54894</th>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.075689</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.306111</td>\n",
       "      <td>0.056780</td>\n",
       "      <td>0.318333</td>\n",
       "      <td>0.011564</td>\n",
       "      <td>0.982654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8611</th>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.012662</td>\n",
       "      <td>0.098472</td>\n",
       "      <td>0.306111</td>\n",
       "      <td>0.129046</td>\n",
       "      <td>0.681389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119389</th>\n",
       "      <td>0.006806</td>\n",
       "      <td>0.036579</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.511998</td>\n",
       "      <td>0.318333</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.982654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        card1_frequency  card2_frequency  card3_frequency  card4_frequency  \\\n",
       "54894          0.000278         0.075689         0.878333         0.306111   \n",
       "8611           0.007222         0.012662         0.098472         0.306111   \n",
       "119389         0.006806         0.036579         0.878333         0.655000   \n",
       "\n",
       "        card5_frequency  card6_frequency  addr1_frequency  addr2_frequency  \n",
       "54894          0.056780         0.318333         0.011564         0.982654  \n",
       "8611           0.129046         0.681389              NaN              NaN  \n",
       "119389         0.511998         0.318333         0.002657         0.982654  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_ce[current_features].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features += current_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.74689\tvalidation_1-auc:0.61405\n",
      "[100]\tvalidation_0-auc:0.96227\tvalidation_1-auc:0.88608\n",
      "[200]\tvalidation_0-auc:0.96627\tvalidation_1-auc:0.89160\n",
      "[300]\tvalidation_0-auc:0.96732\tvalidation_1-auc:0.89423\n",
      "[400]\tvalidation_0-auc:0.96762\tvalidation_1-auc:0.89487\n",
      "[500]\tvalidation_0-auc:0.96812\tvalidation_1-auc:0.89526\n",
      "[547]\tvalidation_0-auc:0.96816\tvalidation_1-auc:0.89533\n",
      "\n",
      "model_3:\n",
      "{'train': 0.9680987679067595, 'valid': 0.8955527528843812, 'test': 0.892033682595582}\n"
     ]
    }
   ],
   "source": [
    "model_fit(model, \n",
    "          x_train_ce, \n",
    "          y_train, \n",
    "          x_valid_ce,\n",
    "          y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.9669344962919636,\n",
       " 'valid': 0.8933799484021945,\n",
       " 'test': 0.8885643055143918}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['model_2']['scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока, всё хуже первых двух, но, наверное, нужно просто выкидывать некоторые признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 4: \n",
    "Создать признаки на основе отношения: TransactionAmt к вычисленной статистике. Статистика - среднее значение / стандартное отклонение TransactionAmt, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_features = ['card1', 'card2', 'card3', \n",
    "                    'card4', 'card5', 'card6', \n",
    "                    'addr1', 'addr2', 'card1_2', \n",
    "                    'card1_2_3_5', 'card1_2_3_5_addr1_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_func_aggregate(dfs, features, stat_feature):\n",
    "    out_dfs = []\n",
    "    for df in dfs:\n",
    "        out_df = df.copy()\n",
    "        for feature in features:\n",
    "            tmp_df = pd.DataFrame()\n",
    "            new_name = f'{feature}_{stat_feature}_stat'\n",
    "            feature_groupby = df.groupby(feature, as_index=False)\n",
    "            tmp_df = feature_groupby[stat_feature].mean()\n",
    "            tmp_df = tmp_df / feature_groupby[stat_feature].std()\n",
    "            tmp_df = tmp_df.rename(columns={stat_feature: new_name})\n",
    "            out_df = out_df.merge(tmp_df, how=\"left\", on=feature)   \n",
    "        out_dfs.append(out_df)\n",
    "    return out_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_ce, x_valid_ce, x_test_ce, x_LB_ce = temp_func_aggregate(\n",
    "        dfs=[x_train_ce, x_valid_ce, x_test_ce, x_LB_ce], \n",
    "        features=current_features, \n",
    "        stat_feature='TransactionAmt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_features = list(map(lambda x: x + '_TransactionAmt_stat', current_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features += current_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.74689\tvalidation_1-auc:0.61405\n",
      "[100]\tvalidation_0-auc:0.96227\tvalidation_1-auc:0.88608\n",
      "[200]\tvalidation_0-auc:0.96627\tvalidation_1-auc:0.89160\n",
      "[300]\tvalidation_0-auc:0.96732\tvalidation_1-auc:0.89423\n",
      "[400]\tvalidation_0-auc:0.96762\tvalidation_1-auc:0.89487\n",
      "[500]\tvalidation_0-auc:0.96812\tvalidation_1-auc:0.89526\n",
      "[547]\tvalidation_0-auc:0.96816\tvalidation_1-auc:0.89533\n",
      "\n",
      "model_4:\n",
      "{'train': 0.9680987679067595, 'valid': 0.8955527528843812, 'test': 0.892033682595582}\n"
     ]
    }
   ],
   "source": [
    "model_fit(model, \n",
    "          x_train_ce, \n",
    "          y_train, \n",
    "          x_valid_ce,\n",
    "          y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.9680987679067595,\n",
       " 'valid': 0.8955527528843812,\n",
       " 'test': 0.892033682595582}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['model_3']['scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На уровне предыдущей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 5: \n",
    "Создать признаки на основе отношения: D15 к вычисленной статистике. Статистика - среднее значение / стандартное отклонение D15, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_features = ['card1', 'card2', 'card3', \n",
    "                    'card4', 'card5', 'card6', \n",
    "                    'addr1', 'addr2', 'card1_2', \n",
    "                    'card1_2_3_5', 'card1_2_3_5_addr1_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ce, x_valid_ce, x_test_ce, x_LB_ce = temp_func_aggregate(\n",
    "        dfs=[x_train_ce, x_valid_ce, x_test_ce, x_LB_ce], \n",
    "        features=current_features, \n",
    "        stat_feature='D15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_features = list(map(lambda x: x + '_TransactionAmt_stat', current_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features += current_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.74689\tvalidation_1-auc:0.61405\n",
      "[100]\tvalidation_0-auc:0.96227\tvalidation_1-auc:0.88608\n",
      "[200]\tvalidation_0-auc:0.96627\tvalidation_1-auc:0.89160\n",
      "[300]\tvalidation_0-auc:0.96732\tvalidation_1-auc:0.89423\n",
      "[400]\tvalidation_0-auc:0.96762\tvalidation_1-auc:0.89487\n",
      "[500]\tvalidation_0-auc:0.96812\tvalidation_1-auc:0.89526\n",
      "[548]\tvalidation_0-auc:0.96816\tvalidation_1-auc:0.89533\n",
      "\n",
      "model_5:\n",
      "{'train': 0.9680987679067595, 'valid': 0.8955527528843812, 'test': 0.892033682595582}\n"
     ]
    }
   ],
   "source": [
    "model_fit(model, \n",
    "          x_train_ce, \n",
    "          y_train, \n",
    "          x_valid_ce,\n",
    "          y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.9680987679067595,\n",
       " 'valid': 0.8955527528843812,\n",
       " 'test': 0.892033682595582}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['model_4']['scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не видно изменений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 6: \n",
    "выделить дробную часть и целую часть признака TransactionAmt в два отдельных признака. После создать отдельных признак - логарифм от TransactionAmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_int_part(x):\n",
    "    return int(x)\n",
    "def get_float_part(x):\n",
    "    return round(x%1, 2) * 100\n",
    "def get_log(x):\n",
    "    return np.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_features = ['get_int_part', 'get_float_part', 'get_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in current_features:\n",
    "    transform_x(dfs=[x_train_ce, x_valid_ce, x_test_ce, x_LB_ce],\n",
    "            column='TransactionAmt',\n",
    "            func=eval(f'{feature}'),\n",
    "            new_column=f'TransactionAmt_{feature}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_features = list(map(lambda x: 'TransactionAmt_' + x, current_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionAmt_get_int_part</th>\n",
       "      <th>TransactionAmt_get_float_part</th>\n",
       "      <th>TransactionAmt_get_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3.432373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.703782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionAmt_get_int_part  TransactionAmt_get_float_part  \\\n",
       "0                           50                            0.0   \n",
       "1                           30                           95.0   \n",
       "2                          300                            0.0   \n",
       "\n",
       "   TransactionAmt_get_log  \n",
       "0                3.912023  \n",
       "1                3.432373  \n",
       "2                5.703782  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_ce[current_features].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features += current_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.74689\tvalidation_1-auc:0.61405\n",
      "[100]\tvalidation_0-auc:0.96253\tvalidation_1-auc:0.88624\n",
      "[200]\tvalidation_0-auc:0.96624\tvalidation_1-auc:0.89335\n",
      "[300]\tvalidation_0-auc:0.96732\tvalidation_1-auc:0.89511\n",
      "[400]\tvalidation_0-auc:0.96762\tvalidation_1-auc:0.89539\n",
      "[402]\tvalidation_0-auc:0.96762\tvalidation_1-auc:0.89539\n",
      "\n",
      "model_6:\n",
      "{'train': 0.9675140089516863, 'valid': 0.8954644176634416, 'test': 0.887677260761171}\n"
     ]
    }
   ],
   "source": [
    "model_fit(model, \n",
    "          x_train_ce, \n",
    "          y_train, \n",
    "          x_valid_ce,\n",
    "          y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.9680987679067595,\n",
       " 'valid': 0.8955527528843812,\n",
       " 'test': 0.892033682595582}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['model_5']['scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сравнению с последними оценками, эта, конечно, чуть лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 7 (опция): \n",
    "выполнить предварительную подготовку / очистку признаков P_emaildomain и R_emaildomain (что и как делать - остается на ваше усмотрение) и сделать Frequency Encoding для очищенных признаков."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
