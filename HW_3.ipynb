{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание 3\n",
    "Ссылка на данные - https://drive.google.com/file/d/1gMEVl47pIoV1-AseB9doQ6DZNJrY3NkW/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Основное задание:\n",
    "Даны выборки для обучения и для тестирования. Задание заключается в том, чтобы попробовать разные способы валидации, проанализировать плюсы / минусы каждой и сделать выводы о том, какой способ валидации наиболее устойчивый в данной задаче. Метрика качества для оценки прогнозов - ROC-AUC, название целевой переменной - IsFraud. Рекомендуется использовать модели градиетного бустинга, реализация любая / гипепараметры любые. Внимание! выборка assignment_2_test.csv - наш аналог лидерборда. Будем моделировать ситуацию отправки решения на лидерборд и сравнить значение метрики на лидерборде и на локальной валидации. Для других целей использовать выборку запрещено!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Терминалогия, используемая в задании:\n",
    "* обучающая выборка - выборка, которая передается в метод fit / train;\n",
    "* валидационная выборка - выборка, которая получается при Hold-Out на 2 выборки (train, valid);\n",
    "* тестовая выборка - выборка, которая получается при Hold-Out на 3 выборки (train, valid, test);\n",
    "* ЛБ - лидерборд, выборка assignment_2_test.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "from sklearn.metrics import r2_score, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from inspect import signature\n",
    "from typing import List, Optional, Union\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from category_encoders.cat_boost import CatBoostEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./assignment_2_train.csv')\n",
    "lb_data = pd.read_csv('./assignment_2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "2  NaN   NaN   NaN   NaN  \n",
       "3  NaN   NaN   NaN   NaN  \n",
       "4  0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180000, 394), (100001, 394))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, lb_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 180000 entries, 0 to 179999\n",
      "Columns: 394 entries, TransactionID to V339\n",
      "dtypes: float64(376), int64(4), object(14)\n",
      "memory usage: 541.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[target_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1: \n",
    "сделать Hold-Out валидацию с разбиением, размер которого будет адеквтаным, по вашему мнению; разбиение проводить по id-транзакции (TransactionID), обучать модель градиетного бустинга любой реализации с подбором числа деревьев по early_stopping критерию до достижения сходимости. Оценить качество модели на валидационной выборке, оценить расхождение по сравнению с качеством на обучающей выборке и валидационной выборке. Оценить качество на ЛБ, сравнить с качеством на обучении и валидации. Сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = 144000 rows, 392 cols\n",
      "x_valid.shape = 36000 rows, 392 cols\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid = train_test_split(\n",
    "    data.drop([\"TransactionID\", target_name], axis=1), train_size=0.8, shuffle=True, random_state=1,\n",
    ")\n",
    "y_train, y_valid = train_test_split(\n",
    "    data[target_name], train_size=0.8, shuffle=True, random_state=1,\n",
    ")\n",
    "\n",
    "numerical_features = x_train.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "categorical_features = x_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "data[categorical_features] = data[categorical_features].astype(str)\n",
    "lb_data[categorical_features] = lb_data[categorical_features].astype(str)\n",
    "x_train[categorical_features] = data[categorical_features].astype(str)\n",
    "x_valid[categorical_features] = data[categorical_features].astype(str)\n",
    "\n",
    "print(\"x_train.shape = {} rows, {} cols\".format(*x_train.shape))\n",
    "print(\"x_valid.shape = {} rows, {} cols\".format(*x_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_LB = lb_data.drop([\"TransactionID\", target_name], axis=1)\n",
    "y_LB = lb_data[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "train_scores = dict() \n",
    "valid_scores = dict()\n",
    "LB_scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductCD:\n",
      "W    88239\n",
      "H    17948\n",
      "R    17626\n",
      "C    17306\n",
      "S     2881\n",
      "Name: ProductCD, dtype: int64\n",
      "\n",
      "card4:\n",
      "visa                94661\n",
      "mastercard          43532\n",
      "american express     3880\n",
      "discover             1920\n",
      "nan                     7\n",
      "Name: card4, dtype: int64\n",
      "\n",
      "card6:\n",
      "debit              98117\n",
      "credit             45861\n",
      "debit or credit        9\n",
      "charge card            7\n",
      "nan                    6\n",
      "Name: card6, dtype: int64\n",
      "\n",
      "P_emaildomain:\n",
      "gmail.com           53894\n",
      "yahoo.com           23318\n",
      "nan                 22595\n",
      "hotmail.com         11971\n",
      "anonymous.com       10644\n",
      "aol.com              6857\n",
      "comcast.net          2362\n",
      "icloud.com           1325\n",
      "outlook.com          1169\n",
      "msn.com              1137\n",
      "att.net               996\n",
      "sbcglobal.net         883\n",
      "verizon.net           784\n",
      "live.com              718\n",
      "bellsouth.net         550\n",
      "ymail.com             523\n",
      "me.com                497\n",
      "cox.net               458\n",
      "yahoo.com.mx          402\n",
      "optonline.net         299\n",
      "charter.net           295\n",
      "live.com.mx           190\n",
      "mac.com               180\n",
      "rocketmail.com        155\n",
      "earthlink.net         138\n",
      "mail.com              120\n",
      "gmail                 101\n",
      "outlook.es            101\n",
      "roadrunner.com         95\n",
      "juno.com               92\n",
      "embarqmail.com         81\n",
      "windstream.net         78\n",
      "twc.com                73\n",
      "hotmail.es             65\n",
      "frontier.com           63\n",
      "q.com                  58\n",
      "hotmail.fr             55\n",
      "web.de                 55\n",
      "netzero.com            55\n",
      "prodigy.net.mx         52\n",
      "aim.com                50\n",
      "cfl.rr.com             50\n",
      "frontiernet.net        41\n",
      "suddenlink.net         38\n",
      "centurylink.net        36\n",
      "sc.rr.com              36\n",
      "netzero.net            36\n",
      "cableone.net           31\n",
      "yahoo.es               31\n",
      "gmx.de                 30\n",
      "yahoo.fr               27\n",
      "yahoo.de               21\n",
      "ptd.net                19\n",
      "yahoo.co.uk            17\n",
      "protonmail.com         15\n",
      "live.fr                12\n",
      "hotmail.co.uk           9\n",
      "servicios-ta.com        8\n",
      "yahoo.co.jp             6\n",
      "hotmail.de              3\n",
      "Name: P_emaildomain, dtype: int64\n",
      "\n",
      "R_emaildomain:\n",
      "nan                95777\n",
      "gmail.com          19769\n",
      "hotmail.com         8120\n",
      "anonymous.com       7823\n",
      "yahoo.com           4542\n",
      "                   ...  \n",
      "sc.rr.com              6\n",
      "centurylink.net        5\n",
      "protonmail.com         4\n",
      "hotmail.de             3\n",
      "scranton.edu           2\n",
      "Name: R_emaildomain, Length: 61, dtype: int64\n",
      "\n",
      "M1:\n",
      "nan    94588\n",
      "T      49411\n",
      "F          1\n",
      "Name: M1, dtype: int64\n",
      "\n",
      "M2:\n",
      "nan    94588\n",
      "T      44499\n",
      "F       4913\n",
      "Name: M2, dtype: int64\n",
      "\n",
      "M3:\n",
      "nan    94588\n",
      "T      38848\n",
      "F      10564\n",
      "Name: M3, dtype: int64\n",
      "\n",
      "M4:\n",
      "nan    77424\n",
      "M0     40985\n",
      "M2     14884\n",
      "M1     10707\n",
      "Name: M4, dtype: int64\n",
      "\n",
      "M5:\n",
      "nan    94653\n",
      "F      27480\n",
      "T      21867\n",
      "Name: M5, dtype: int64\n",
      "\n",
      "M6:\n",
      "nan    59497\n",
      "F      45296\n",
      "T      39207\n",
      "Name: M6, dtype: int64\n",
      "\n",
      "M7:\n",
      "nan    118614\n",
      "F       21726\n",
      "T        3660\n",
      "Name: M7, dtype: int64\n",
      "\n",
      "M8:\n",
      "nan    118614\n",
      "F       15925\n",
      "T        9461\n",
      "Name: M8, dtype: int64\n",
      "\n",
      "M9:\n",
      "nan    118614\n",
      "T       21623\n",
      "F        3763\n",
      "Name: M9, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in categorical_features:\n",
    "    print(f'{feature}:\\n{x_train[feature].value_counts()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Обработка категориальных признаков и подготовка матрицы\n",
    "    признаков для передачи в любой алгоритм машинного обучения.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    encoder: callable\n",
    "        Объект для обработки категориальных признаков;\n",
    "        объект должен поддерживать sklearn-API.\n",
    "\n",
    "    categorical_features: List[str]\n",
    "        Список с названием категориальных признаков.\n",
    "\n",
    "    na_value: float or str, optional, default = None\n",
    "        Значение для заполнения пропусков.\n",
    "        Опциональный параметр, по умолчанию, не используется.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 encoder: callable,\n",
    "                 categorical_features: List[str],\n",
    "                 na_value: Union[int, float, str] = None) -> None:\n",
    "        self.encoder = encoder\n",
    "        self.categorical_features = categorical_features\n",
    "        self.na_value = na_value\n",
    "\n",
    "        sig = signature(encoder.fit)\n",
    "        self.nparams = len(sig.parameters)\n",
    "        self.encoders = None\n",
    "\n",
    "    def _prepare_data(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Подготовка данных для передачи в модель.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.na_value:\n",
    "            return X[self.categorical_features].fillna(self.na_value)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _check_unique_values(self, y: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Проверка на ранее не встречающиеся значения признака.\n",
    "        Если значения встречаются - заменяем на self.na_value,\n",
    "        если self.na_value - не задан, то заменяем на моду.\n",
    "\n",
    "        \"\"\"\n",
    "        encoder = self.encoders[y.name]\n",
    "        missed_values = list(\n",
    "            set(y.unique()) - set(encoder.classes_)\n",
    "        )\n",
    "\n",
    "        if missed_values:\n",
    "            mask = y.isin(missed_values)\n",
    "            if self.na_value:\n",
    "                y[mask] = self.na_value\n",
    "            else:\n",
    "                mode = y.value_counts()[0].index\n",
    "                y[mask] = mode\n",
    "\n",
    "        return y\n",
    "\n",
    "    def _fit_label_encoder(self, X: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Обучение LabelEncoder'ов для всех признаков;\n",
    "\n",
    "        \"\"\"\n",
    "        self.encoders = {}\n",
    "        for feature in self.categorical_features:\n",
    "            x = X[feature].astype(str)\n",
    "            encoder = deepcopy(self.encoder)\n",
    "            self.encoders[feature] = encoder.fit(x)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _transform_label_encoder(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Применение LabelEncoder'ов для всех признаков;\n",
    "\n",
    "        \"\"\"\n",
    "        for feature in self.categorical_features:\n",
    "            x = X[feature].astype(str)\n",
    "            x = self._check_unique_values(x)\n",
    "            encoder = self.encoders.get(feature)\n",
    "            X[feature] = encoder.transform(x)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Обучение encoder'а категориальных признаков.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: pandas.core.frame.DataFrame\n",
    "            Матрица признаков.\n",
    "\n",
    "        y: pandas.core.frame.Series\n",
    "            Вектор целевой переменной.\n",
    "            Опциональный параметр, по умолчанию, не требуется.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        X = self._prepare_data(X)\n",
    "        if self.nparams == 1:\n",
    "            self._fit_label_encoder(X=X)\n",
    "        else:\n",
    "            self.encoder.fit(\n",
    "                X[self.categorical_features].astype(str), y\n",
    "            )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Преобразование категориальных признаков.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: pandas.core.frame.DataFrame\n",
    "            Матрица признаков.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_transformed: pandas.core.frame.DataFrame\n",
    "            Преобразованная матрица признаков с\n",
    "            обработанными категориальными признаками.\n",
    "\n",
    "        \"\"\"\n",
    "        X = self._prepare_data(X)\n",
    "        if self.encoders:\n",
    "            categorical = self._transform_label_encoder(X)\n",
    "        else:\n",
    "            categorical = self.encoder.transform(\n",
    "                X[self.categorical_features].astype(str)\n",
    "            )\n",
    "\n",
    "        X = X.drop(self.categorical_features, axis=1)\n",
    "        X = pd.concat([X, categorical], axis=1)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"n_estimators\": 1000,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"reg_lambda\": 10,\n",
    "    \"max_depth\": 4,\n",
    "    \"gamma\": 10,\n",
    "#     \"nthread\": 6,\n",
    "    \"seed\": 27,\n",
    "    'predictor': 'gpu_predictor',\n",
    "    'tree_method': 'gpu_hist'\n",
    "}\n",
    "eval_sets = [\n",
    "    (x_train[numerical_features], y_train),\n",
    "    (x_valid[numerical_features], y_valid)\n",
    "]\n",
    "xgb_model = xgb.XGBClassifier(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CategoricalEncoder(\n",
    "    encoder=CatBoostEncoder(random_state=27),\n",
    "    categorical_features=categorical_features,\n",
    ")\n",
    "\n",
    "x_train_catboost_encoder = encoder.fit_transform(x_train, y_train)\n",
    "x_valid_catboost_encoder = encoder.transform(x_valid)\n",
    "x_LB_catboost_encoder = encoder.transform(x_LB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.63480\tvalidation_1-auc:0.63095\n",
      "[10]\tvalidation_0-auc:0.79506\tvalidation_1-auc:0.79917\n",
      "[20]\tvalidation_0-auc:0.84301\tvalidation_1-auc:0.83794\n",
      "[30]\tvalidation_0-auc:0.87867\tvalidation_1-auc:0.87073\n",
      "[40]\tvalidation_0-auc:0.88939\tvalidation_1-auc:0.88006\n",
      "[50]\tvalidation_0-auc:0.89902\tvalidation_1-auc:0.88802\n",
      "[60]\tvalidation_0-auc:0.90598\tvalidation_1-auc:0.89331\n",
      "[70]\tvalidation_0-auc:0.91081\tvalidation_1-auc:0.89810\n",
      "[80]\tvalidation_0-auc:0.91436\tvalidation_1-auc:0.90055\n",
      "[90]\tvalidation_0-auc:0.91654\tvalidation_1-auc:0.90272\n",
      "[100]\tvalidation_0-auc:0.91880\tvalidation_1-auc:0.90440\n",
      "[110]\tvalidation_0-auc:0.92114\tvalidation_1-auc:0.90602\n",
      "[120]\tvalidation_0-auc:0.92225\tvalidation_1-auc:0.90683\n",
      "[130]\tvalidation_0-auc:0.92225\tvalidation_1-auc:0.90683\n",
      "[140]\tvalidation_0-auc:0.92225\tvalidation_1-auc:0.90683\n",
      "[150]\tvalidation_0-auc:0.92225\tvalidation_1-auc:0.90683\n",
      "[160]\tvalidation_0-auc:0.92225\tvalidation_1-auc:0.90683\n",
      "[165]\tvalidation_0-auc:0.92225\tvalidation_1-auc:0.90683\n"
     ]
    }
   ],
   "source": [
    "eval_sets = [\n",
    "    (x_train_catboost_encoder, y_train),\n",
    "    (x_valid_catboost_encoder, y_valid)\n",
    "]\n",
    "\n",
    "xgb_model.fit(\n",
    "    y=y_train,\n",
    "    X=x_train_catboost_encoder,\n",
    "    early_stopping_rounds=50,\n",
    "    eval_set=eval_sets,\n",
    "    eval_metric=\"auc\",\n",
    "    verbose=10\n",
    ")\n",
    "models[\"Hold_Out_2_samples\"] = xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_scores[\"Hold_Out_2_samples\"] = xgb_model.predict_proba(\n",
    "    x_train_catboost_encoder)[:,1]\n",
    "valid_scores[\"Hold_Out_2_samples\"] = xgb_model.predict_proba(\n",
    "    x_valid_catboost_encoder)[:,1]\n",
    "LB_scores[\"Hold_Out_2_samples\"] = xgb_model.predict_proba(\n",
    "    x_LB_catboost_encoder)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9222458779220862 0.9068308037904418 0.8616211265204365\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train, train_scores[\"Hold_Out_2_samples\"]),\n",
    "roc_auc_score(y_valid, valid_scores[\"Hold_Out_2_samples\"]),\n",
    "roc_auc_score(y_LB, LB_scores[\"Hold_Out_2_samples\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество на ЛБ заметно ниже, чем на валидной выборке. Данные, которые не видела модель, дествительно полезны для оценки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2: \n",
    "сделать Hold-Out валидацию с разбиением на 3 выборки, разбиение проводить по id-транзакции (TransactionID), размер каждой выборки подобрать самостоятельно. Повторить процедуру из п.1. для каждой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = 144000 rows, 392 cols\n",
      "x_valid.shape = 28800 rows, 392 cols\n",
      "x_test.shape = 7200 rows, 392 cols\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid = train_test_split(\n",
    "    data.drop([\"TransactionID\", target_name], axis=1), train_size=0.8, shuffle=True, random_state=1,\n",
    ")\n",
    "y_train, y_valid = train_test_split(\n",
    "    data[target_name], train_size=0.8, shuffle=True, random_state=1,\n",
    ")\n",
    "\n",
    "x_valid, x_test = train_test_split(\n",
    "    x_valid, train_size=0.8, shuffle=True, random_state=27\n",
    ")\n",
    "y_valid, y_test = train_test_split(\n",
    "    y_valid, train_size=0.8, shuffle=True, random_state=27\n",
    ")\n",
    "\n",
    "print(\"x_train.shape = {} rows, {} cols\".format(*x_train.shape))\n",
    "print(\"x_valid.shape = {} rows, {} cols\".format(*x_valid.shape))\n",
    "print(\"x_test.shape = {} rows, {} cols\".format(*x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CategoricalEncoder(\n",
    "    encoder=CatBoostEncoder(random_state=27),\n",
    "    categorical_features=categorical_features,\n",
    ")\n",
    "\n",
    "x_train_catboost_encoder = encoder.fit_transform(x_train, y_train)\n",
    "x_valid_catboost_encoder = encoder.transform(x_valid)\n",
    "x_test_catboost_encoder = encoder.transform(x_test)\n",
    "x_LB_catboost_encoder = encoder.transform(x_LB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.63480\tvalidation_1-auc:0.63569\n",
      "[10]\tvalidation_0-auc:0.79506\tvalidation_1-auc:0.80038\n",
      "[20]\tvalidation_0-auc:0.84301\tvalidation_1-auc:0.83709\n",
      "[30]\tvalidation_0-auc:0.87867\tvalidation_1-auc:0.87189\n",
      "[40]\tvalidation_0-auc:0.88939\tvalidation_1-auc:0.88068\n",
      "[50]\tvalidation_0-auc:0.89902\tvalidation_1-auc:0.88891\n",
      "[60]\tvalidation_0-auc:0.90598\tvalidation_1-auc:0.89399\n",
      "[70]\tvalidation_0-auc:0.91081\tvalidation_1-auc:0.89897\n",
      "[80]\tvalidation_0-auc:0.91436\tvalidation_1-auc:0.90106\n",
      "[90]\tvalidation_0-auc:0.91654\tvalidation_1-auc:0.90311\n",
      "[100]\tvalidation_0-auc:0.91880\tvalidation_1-auc:0.90461\n",
      "[110]\tvalidation_0-auc:0.92114\tvalidation_1-auc:0.90616\n",
      "[120]\tvalidation_0-auc:0.92225\tvalidation_1-auc:0.90682\n",
      "[130]\tvalidation_0-auc:0.92225\tvalidation_1-auc:0.90682\n",
      "[140]\tvalidation_0-auc:0.92225\tvalidation_1-auc:0.90682\n",
      "[150]\tvalidation_0-auc:0.92225\tvalidation_1-auc:0.90682\n",
      "[160]\tvalidation_0-auc:0.92225\tvalidation_1-auc:0.90682\n",
      "[165]\tvalidation_0-auc:0.92225\tvalidation_1-auc:0.90682\n"
     ]
    }
   ],
   "source": [
    "eval_sets = [\n",
    "    (x_train_catboost_encoder, y_train),\n",
    "    (x_valid_catboost_encoder, y_valid)\n",
    "]\n",
    "\n",
    "xgb_model.fit(\n",
    "    y=y_train,\n",
    "    X=x_train_catboost_encoder,\n",
    "    early_stopping_rounds=50,\n",
    "    eval_set=eval_sets,\n",
    "    eval_metric=\"auc\",\n",
    "    verbose=10\n",
    ")\n",
    "models[\"Hold_Out_3_samples\"] = xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_scores[\"Hold_Out_3_samples\"] = xgb_model.predict_proba(\n",
    "    x_train_catboost_encoder)[:,1]\n",
    "valid_scores[\"Hold_Out_3_samples\"] = xgb_model.predict_proba(\n",
    "    x_valid_catboost_encoder)[:,1]\n",
    "test_scores[\"Hold_Out_3_samples\"] = xgb_model.predict_proba(\n",
    "    x_test_catboost_encoder)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9222458779220862 0.9068231217922476 0.9067992817169057\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train, train_scores[\"Hold_Out_3_samples\"]),\n",
    "roc_auc_score(y_valid, valid_scores[\"Hold_Out_3_samples\"]),\n",
    "roc_auc_score(y_test, test_scores[\"Hold_Out_3_samples\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3: \n",
    "построить доверительный интервал на данных из п.2 на основе бутстреп выборок, оценить качество модели на ЛБ относительно полученного доверительного интервала. Сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bootstrap_samples(data: np.array, n_samples: int = 1000) -> np.array:\n",
    "    \"\"\"\n",
    "    Создание бутстреп-выборок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.array\n",
    "        Исходная выборка, которая будет использоваться для\n",
    "        создания бутстреп выборок.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_idx: np.array\n",
    "        Матрица индексов, для создания бутстреп выборок.\n",
    "\n",
    "    \"\"\"\n",
    "    bootstrap_idx = np.random.randint(\n",
    "        low=0, high=len(data), size=(n_samples, len(data))\n",
    "    )\n",
    "    return bootstrap_idx\n",
    "\n",
    "\n",
    "def create_bootstrap_metrics(y_true: np.array,\n",
    "                             y_pred: np.array,\n",
    "                             metric: callable,\n",
    "                             n_samlpes: int = 1000) -> List[float]:\n",
    "    \"\"\"\n",
    "    Вычисление бутстреп оценок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: np.array\n",
    "        Вектор целевой переменной.\n",
    "\n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов.\n",
    "\n",
    "    metric: callable\n",
    "        Функция для вычисления метрики.\n",
    "        Функция должна принимать 2 аргумента: y_true, y_pred.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_metrics: List[float]\n",
    "        Список со значениями метрики качества на каждой бустреп выборке.\n",
    "\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    if isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    bootstrap_idx = create_bootstrap_samples(y_true, n_samples=n_samlpes)\n",
    "    for idx in bootstrap_idx:\n",
    "        y_true_bootstrap = y_true[idx]\n",
    "        y_pred_bootstrap = y_pred[idx]\n",
    "\n",
    "        score = metric(y_true_bootstrap, y_pred_bootstrap)\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def calculate_confidence_interval(scores: list, conf_interval: float = 0.95) -> Tuple[float]:\n",
    "    \"\"\"\n",
    "    Вычисление доверительного интервала.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores: List[float / int]\n",
    "        Список с оценками изучаемой величины.\n",
    "\n",
    "    conf_interval: float, optional, default = 0.95\n",
    "        Уровень доверия для построения интервала.\n",
    "        Опциональный параметр, по умолчанию, равен 0.95.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    conf_interval: Tuple[float]\n",
    "        Кортеж с границами доверительного интервала.\n",
    "\n",
    "    \"\"\"\n",
    "    left_bound = np.percentile(\n",
    "        scores, ((1 - conf_interval) / 2) * 100\n",
    "    )\n",
    "    right_bound = np.percentile(\n",
    "        scores, (conf_interval + ((1 - conf_interval) / 2)) * 100\n",
    "    )\n",
    "\n",
    "    return left_bound, right_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.907      [0.880 : 0.931]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(27)\n",
    "scores = create_bootstrap_metrics(y_test, \n",
    "                                  xgb_model.predict_proba(x_test_catboost_encoder)[:,1], \n",
    "                                  roc_auc_score)\n",
    "\n",
    "interval = calculate_confidence_interval(scores)\n",
    "print(f'roc_auc_score: {roc_auc_score(y_test, test_scores[\"Hold_Out_3_samples\"]):.3f}\\\n",
    "      [{interval[0]:.3f} : {interval[1]:.3f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LB_scores[\"Hold_Out_3_samples\"] = xgb_model.predict_proba(\n",
    "    x_LB_catboost_encoder)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8616211265204365"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_LB, LB_scores[\"Hold_Out_3_samples\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что оценка на ЛБ не попадает в доверительный интервал, значит модель переобучена или тестовые данные имеют иное распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4: \n",
    "выполнить Adversarial Validation, подобрать объекты из обучающей выборки, которые сильно похожи на объекты из assignment_2_test.csv, и использовать их в качестве валидационного набора. Оценить качество модели на ЛБ, сделать выводы о полученных результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv = pd.concat([\n",
    "    x_train_catboost_encoder, x_LB_catboost_encoder], axis=0\n",
    ")\n",
    "y_adv = np.hstack((np.zeros(x_train_catboost_encoder.shape[0]), np.ones(x_LB_catboost_encoder.shape[0])))\n",
    "assert x_adv.shape[0] == y_adv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=25, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_model = xgb.XGBClassifier(n_estimators=25)\n",
    "adv_model.fit(x_adv, y_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00\n"
     ]
    }
   ],
   "source": [
    "y_pred_adv = adv_model.predict_proba(x_adv)\n",
    "adv_score = roc_auc_score(y_adv, y_pred_adv[:, 1])\n",
    "print(f'{adv_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9974763e-01, 2.5233824e-04],\n",
       "       [9.9974763e-01, 2.5233824e-04],\n",
       "       [9.9974763e-01, 2.5233824e-04],\n",
       "       ...,\n",
       "       [9.9974763e-01, 2.5233824e-04],\n",
       "       [9.9974763e-01, 2.5233824e-04],\n",
       "       [9.9974763e-01, 2.5233824e-04]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = adv_model.predict_proba(x_train_catboost_encoder)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1]    144000\n",
       "(0.1, 0.2]         0\n",
       "(0.2, 0.3]         0\n",
       "(0.3, 0.4]         0\n",
       "(0.4, 0.5]         0\n",
       "(0.5, 0.6]         0\n",
       "(0.6, 0.7]         0\n",
       "(0.7, 0.8]         0\n",
       "(0.8, 0.9]         0\n",
       "(0.9, 1.0]         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cut = pd.cut(y_pred[:, 1], bins=np.arange(0, 1.01, 0.1))\n",
    "y_pred_cut.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244001, 392)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_adv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так я и не понял, что с этим делать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим почему так хорошо тестовая выборка отличается от тренировочной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ntop = 10\n",
    "importances = adv_model.feature_importances_\n",
    "idx = np.argsort(importances)[::-1][0:ntop]\n",
    "feature_names = x_train_catboost_encoder.columns.values\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.barplot(x=feature_names[idx], y=importances[idx], palette=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наверное, можно было бы попробовать обучаться без 'TransactionDT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dropDT = x_train_catboost_encoder.drop('TransactionDT', axis=1)\n",
    "x_valid_dropDT = x_valid_catboost_encoder.drop('TransactionDT', axis=1)\n",
    "x_test_dropDT = x_test_catboost_encoder.drop('TransactionDT', axis=1)\n",
    "x_LB_dropDT = x_LB_catboost_encoder.drop('TransactionDT', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.63480\tvalidation_1-auc:0.63569\n",
      "[10]\tvalidation_0-auc:0.80210\tvalidation_1-auc:0.80509\n",
      "[20]\tvalidation_0-auc:0.84323\tvalidation_1-auc:0.83732\n",
      "[30]\tvalidation_0-auc:0.87441\tvalidation_1-auc:0.86953\n",
      "[40]\tvalidation_0-auc:0.88579\tvalidation_1-auc:0.88003\n",
      "[50]\tvalidation_0-auc:0.89571\tvalidation_1-auc:0.88779\n",
      "[60]\tvalidation_0-auc:0.90232\tvalidation_1-auc:0.89303\n",
      "[70]\tvalidation_0-auc:0.90684\tvalidation_1-auc:0.89728\n",
      "[80]\tvalidation_0-auc:0.91012\tvalidation_1-auc:0.89998\n",
      "[90]\tvalidation_0-auc:0.91216\tvalidation_1-auc:0.90144\n",
      "[100]\tvalidation_0-auc:0.91391\tvalidation_1-auc:0.90242\n",
      "[110]\tvalidation_0-auc:0.91553\tvalidation_1-auc:0.90401\n",
      "[120]\tvalidation_0-auc:0.91585\tvalidation_1-auc:0.90423\n",
      "[130]\tvalidation_0-auc:0.91585\tvalidation_1-auc:0.90423\n",
      "[140]\tvalidation_0-auc:0.91585\tvalidation_1-auc:0.90423\n",
      "[150]\tvalidation_0-auc:0.91585\tvalidation_1-auc:0.90423\n",
      "[160]\tvalidation_0-auc:0.91585\tvalidation_1-auc:0.90423\n",
      "[161]\tvalidation_0-auc:0.91585\tvalidation_1-auc:0.90423\n"
     ]
    }
   ],
   "source": [
    "eval_sets = [\n",
    "    (x_train_dropDT, y_train),\n",
    "    (x_valid_dropDT, y_valid)\n",
    "]\n",
    "\n",
    "xgb_model.fit(\n",
    "    y=y_train,\n",
    "    X=x_train_dropDT,\n",
    "    early_stopping_rounds=50,\n",
    "    eval_set=eval_sets,\n",
    "    eval_metric=\"auc\",\n",
    "    verbose=10\n",
    ")\n",
    "models[\"Hold_Out_3_samples_dropDT\"] = xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_scores[\"Hold_Out_3_samples_dropDT\"] = xgb_model.predict_proba(\n",
    "    x_train_dropDT)[:,1]\n",
    "valid_scores[\"Hold_Out_3_samples_dropDT\"] = xgb_model.predict_proba(\n",
    "    x_valid_dropDT)[:,1]\n",
    "test_scores[\"Hold_Out_3_samples_dropDT\"] = xgb_model.predict_proba(\n",
    "    x_test_dropDT)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9158551136918239 0.9042308202235546 0.8984807963876636\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train, train_scores[\"Hold_Out_3_samples_dropDT\"]),\n",
    "roc_auc_score(y_valid, valid_scores[\"Hold_Out_3_samples_dropDT\"]),\n",
    "roc_auc_score(y_test, test_scores[\"Hold_Out_3_samples_dropDT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.898      [0.870 : 0.923]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(27)\n",
    "scores = create_bootstrap_metrics(y_test, \n",
    "                                  xgb_model.predict_proba(x_test_dropDT)[:,1], \n",
    "                                  roc_auc_score)\n",
    "\n",
    "interval = calculate_confidence_interval(scores)\n",
    "print(f'roc_auc_score: {roc_auc_score(y_test, test_scores[\"Hold_Out_3_samples_dropDT\"]):.3f}\\\n",
    "      [{interval[0]:.3f} : {interval[1]:.3f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "LB_scores[\"Hold_Out_3_samples_dropDT\"] = xgb_model.predict_proba(\n",
    "    x_LB_dropDT)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8650422163719043"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_LB, LB_scores[\"Hold_Out_3_samples_dropDT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество улучшилось, но до доверительного интервала не дотягивает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще раз попробуем, но без DT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv_dropDT = x_adv.drop('TransactionDT', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50\n"
     ]
    }
   ],
   "source": [
    "y_pred_adv = adv_model.predict_proba(x_adv_dropDT)\n",
    "adv_score = roc_auc_score(y_adv, y_pred_adv[:, 1])\n",
    "print(f'{adv_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь данные похожи, но почему тогда оценка не попала в доверительный интервал?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5: \n",
    "сделать KFold / StratifiedKFold валидацию (на ваше усмотрение), оценить получаемые качество и разброс по метрике качества. Сделать выводы об устойчивости кросс-валидации, сходимости оценки на кросс-валидации и отложенном наборе данных; Оценить качество на ЛБ, сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-results: 0.8511 +/- 0.033\n"
     ]
    }
   ],
   "source": [
    "cv = cross_val_score(\n",
    "    estimator=models['Hold_Out_3_samples'],\n",
    "    X=x_test_catboost_encoder,\n",
    "    y=y_test,\n",
    "    scoring='roc_auc',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "print(f\"CV-results: {round(np.mean(cv), 4)} +/- {round(np.std(cv), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-results: 0.8692 +/- 0.012\n"
     ]
    }
   ],
   "source": [
    "cv = cross_val_score(\n",
    "    estimator=models['Hold_Out_3_samples'],\n",
    "    X=x_LB_catboost_encoder,\n",
    "    y=y_LB,\n",
    "    scoring='roc_auc',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "print(f\"CV-results: {round(np.mean(cv), 4)} +/- {round(np.std(cv), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кросс-валидация на трейне сумела вместить в свой доверительный интервал валидацию на ЛБ. Видимо, метрика качества 0.9 была всё-таки выбросом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6 (опциональное): \n",
    "сделать Hold-Out валидацию по времени (TransactionDT), повторить процедуры из п.1 / п.2 (на ваш выбор). Построить доверительный интервал, сравнить качество на ЛБ выборке с полученным доверительным интервалом. Сделать выводы.\n",
    "​\n",
    "Задание 7 (совсем опциональное): в данном наборе данных у нас есть ID-транзакции (TransactionID) и время транзакции (TransactionDT), но отсутствует ID-клиента, который совершал транзакции. Кажется, что в этой задаче валидация по клиенту работала бы хорошо. Предложить критерий, по которому можно выделить клиентов и сделать п.5, используя созданное определение клиента, используя валидацию по клиенту (GroupKFold)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7 (совсем опциональное): \n",
    "в данном наборе данных у нас есть ID-транзакции (TransactionID) и время транзакции (TransactionDT), но отсутствует ID-клиента, который совершал транзакции. Кажется, что в этой задаче валидация по клиенту работала бы хорошо. Предложить критерий, по которому можно выделить клиентов и сделать п.5, используя созданное определение клиента, используя валидацию по клиенту (GroupKFold)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
